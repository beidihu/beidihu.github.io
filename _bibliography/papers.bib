---
---

@article{hu2026when,
  title={When Goods Were Odds: Do People Prefer Goods that Stem from Uncertainty?},
  author={Hu*, Beidi and Yin*, Siyuan and Moon*, Alice},
  year={2025},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4001081},
  researchbox={https://researchbox.org/454&PEER_REVIEW_passcode=DZKWRE},
  abstract={Much of the uncertainty people face is eventually resolved (e.g., a person entered in a raffle eventually learns what prize they have received). How do people evaluate goods (e.g., prizes) resulting from uncertainty (e.g., raffles)? Seven experiments (total N = 12,128) provide evidence for an uncertainty spillover effect: People prefer goods originating from uncertain prospects compared to those that were always known. This effect appears both with naturalistic scenarios (Study 1) and with incentive-compatible decisions (Study 2). We propose this effect arises because uncertainty induces a perception that the outcome is superior relative to salient downward counterfactuals (Study 3). Supporting this idea, this effect: (a) weakened when downward counterfactuals were salient for certain goods (Study 4), (b) weakened when the worst outcome from uncertainty was realized (Study 5), and (c) reversed when uncertainty involved losses (Study 6). Lastly, this effect carried over to products associated with previously uncertain goods (Study 7). These findings demonstrate that the influence of uncertainty persists beyond its resolution, shaping the evaluation of goods derived from uncertainty.},
  summary={Getting a 25-dollar gift card is nice. Getting the same 25-dollar gift card from a lottery where you could’ve gotten something much less somehow feels better. Well, but it's the same 25-dollar gift card after all! This paper examines this phenomenon, its psychology, and its influence. We show that when a good comes from an uncertain source, people naturally compare it to the worse outcomes they avoided, which makes the final outcome feel more valuable. So even after uncertainty is resolved, it affects how we evaluate what we end up with.},
  conferences={Peer-reviewed conference talks at the Association for Consumer Research (ACR) 2024, the American Marketing Association Consumer Behavior Interest Group (AMA CBSIG) 2024, the Behavioral Decision Research in Management (BDRM) 2024, the Society for Consumer Psychology (SCP) 2024, the Society for Judgment and Decision Making (SJDM) 2023, and the Society for Personality and Social Psychology (SPSP) JDM Pre-conference 2023.},    
  work={true}
}

@article{hu2026what,
  title={What are the Different Types of Uncertainty?},
  author={Gaertig*, Celia and Hu*, Beidi and Simmons, Joseph P.},
  year={2025},
  summary={Philosophers, and more recently, psychologists, have drawn a distinction between aleatory uncertainty (coming from chance) and epistemic uncertainty (coming from lack of knowledge). It's a really cool distinction. We find that when people think about what kind of uncertainty (epistemic or aleatory) they are facing, they also factor in how much uncertainty there is.},
  conferences={Peer-reviewed conference talks at the Society for Consumer Psychology (SCP) 2026 (upcoming), the Society for Judgment and Decision-Making (SJDM) 2025, and the Association for Consumer Research (ACR) 2025.},  
  work={true}
}

@article{hu2026thinking,
  title={People Think Off the Margin: Preferentially Improving Outcomes That Are Already More Valuable.},
  author={Lewis, Joshua and Hu, Beidi},
  year={2024},
  psycharchives={https://psycharchives.org/en/item/2e3bc503-eda3-4ad8-b769-a9ac2007aeb2},
  researchbox={https://researchbox.org/3191&PEER_REVIEW_passcode=WDPVUQ},
  abstract={Throughout life, people must decide whether to pursue costly improvements to outcomes they care about. According to classical economics, people think at the margin: that is, they weigh the marginal benefit from an incremental improvement in the outcome against its marginal cost (1). Additionally, economists often assume diminishing marginal benefits from wealth and consumption (2). Thus, there is more marginal benefit from improving a reward from $20 to $30 than from $70 to $80, and even more marginal benefit from reducing a loss from $30 to $20. Similarly, psychologists typically assume diminishing sensitivity to gains and loss aversion (3), implying the same pattern. Yet, contrary to what marginal thinking would predict, across seven experiments (total N = 5,864, five with real consequences), participants tended to improve more versus less favorable outcomes, improving gains more than losses and larger gains more than smaller gains. That is, our participants thought off the margin: they decided on improvements based on the total value of the outcomes, not just the incremental change in their value. We propose that people think off the margin because attaining improvements requires motivation and, in general, people are more motivated to take actions with which they have more positive associations (4). People have more positive associations with improvements when the potential outcomes are more valuable in total, even if the marginal improvement in those outcomes is very small. Thus, in life, people might waste resources improving what is already valuable and neglect to improve what is in need of improvement.},
  summary={You are deciding whether to put in some effort to improve a reward. Would you rather turn a small reward into a slightly larger one, or make an already large reward even better? Most theories say people should focus on where the marginal improvement matters more (in this case, the smaller reward). But in fact, many of us might feel more motivated to improve things that are already going well. This paper explores this idea and finds that when deciding whether to pursue costly improvements, people often think off the margin - they decide based on how good the overall outcome will be, rather than the size of the incremental gain.},
  work={true}
}


@article{hu2023does,
  title={Does Constructing a Belief Distribution Truly Reduce Overconfidence?},
  author={Hu, Beidi and Simmons, Joseph P},
  journal={Journal of Experimental Psychology: General},
  volume={152},
  number={2},
  pages={571},
  year={2023},
  publisher={American Psychological Association},
  doi={https://doi.org/10.1037/xge0001291},
  pdf={https://drive.google.com/file/d/1VQeJd3eVyDd2tWwKvoVtk_wrmSZqFO6C/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4180883},
  supp={https://drive.google.com/file/d/1V68oK10_pcPcvWKorgNAS-GfnTqOHLO1/view?usp=sharing},
  researchbox={https://researchbox.org/314},
  abstract={Can overconfidence be reduced by asking people to provide a belief distribution over all possible outcomes—that is, by asking them to indicate how likely all possible outcomes are? Although prior research suggests that the answer is “yes,” that research suffers from methodological confounds that muddle its interpretation. In our research, we remove these confounds to investigate whether providing a belief distribution truly reduces overconfidence. In 10 studies, participants made predictions about upcoming sports games or other participants’ preferences, and then indicated their confidence in these predictions using rating scales, likelihood judgments, and/or incentivized wagers. Contrary to prior research, and to our own expectations, we find that providing a belief distribution usually increases overconfidence, because doing so seems to reinforce people’s prior beliefs.},
  summary={Past work says yes. Our paper finds the opposite.},
  conferences={Peer-reviewed conference talks at the Society for Personality and Social Psychology (SPSP) 2022 and the Subjective Probabiltiy, Utility, and Decision-Making (SPUDM) 2021.},    
  work={false}
}

@article{hu2025different,
  title={Different Methods Elicit Different Belief Distributions.},
  author={Hu, Beidi and Simmons, Joseph P},
  journal={Journal of Experimental Psychology: General},
  volume={154},
  number={2},
  pages={476},
  year={2025},
  publisher={American Psychological Association},
  doi={https://doi.org/10.1037/xge0001655},
  pdf={https://drive.google.com/file/d/1ICWKU2mY7NsI6m6bhYRP2AUKXPzTm7J6/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4926793},
  supp={https://drive.google.com/file/d/1W6q1PN-IjHcYKfeH4igSL8iUo3vOlbZv/view?usp=sharing},
  researchbox={https://researchbox.org/569},
  abstract={When eliciting people’s forecasts or beliefs, you can ask for a point estimate—for example, what is the most likely state of the world?—or you can ask for an entire distribution of beliefs—for example, how likely is every possible state of the world? Eliciting belief distributions potentially yields more information, and researchers have increasingly tried to do so. In this article, we show that different elicitation methods elicit different belief distributions. We compare two popular methods used to elicit belief distributions: Distribution Builder and Sliders. In 10 preregistered studies (N = 14,553), we find that Distribution Builder elicits more accurate belief distributions than Sliders, except when true distributions are right-skewed, for which the results are mixed. This result holds when we assess accuracy (a) relative to a normative benchmark and (b) relative to participants’ own beliefs. Our evidence suggests that participants approach these two methods differently: Sliders users are more likely to start with the lowest bins in the interface, which in turn leads them to put excessive mass in those bins. Our research sheds light on the process by which people construct belief distributions while offering a practical recommendation for future research: All else equal, Distribution Builder yields more accurate belief distributions.},
  summary={I’ve been long interested in how people really think about uncertain events since even before starting grad school. In my first year of grad school, I learned about this cool thing called belief distributions: instead of asking people for a single best guess about the future, you show them all the possible outcomes and ask how likely each one feels. This paper grew out of my very first grad school project: Okay, but how do we elicit that cool thing in people's heads? In this paper, we find that two commonly used methods in the literature lead to systematically different belief distributions. Do belief distributions really exist in people’s heads? Well, I'm not sure - that’s something I’m trying to figure out in ongoing work. But it's certainly worth keeping in mind that they are shaped by how we ask people to express them.},
  conferences={Peer-reviewed conference talks at the Society for Consumer Psychology (SCP) 2022 and the Association of Consumer Research (ACR) 2021.},    
  work={false}
}

@article{hu2025should,
  title={How Should Time Estimates Be Structured to Increase Customer Satisfaction?},
  author={Hu, Beidi and Gaertig, Celia and Dietvorst, Berkeley J},
  journal={Management Science},
  volume={71},
  number={9},
  pages={7497},
  year={2025},
  publisher={INFORMS},
  doi={https://doi.org/10.1287/mnsc.2023.00137},
  pdf={https://drive.google.com/file/d/1NutuW7y_iAOzTc7ZSVKkAJtM1I5NOI57/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4927151},
  supp={https://drive.google.com/file/d/1auz8ySRF948fTKYOlxUJXZ9DKX5arl7i/view?usp=sharing},
  researchbox={https://researchbox.org/482},
  abstract={Businesses across industries, such as food delivery apps and GPS navigation systems, routinely provide customers with time estimates in inherently uncertain contexts. How does the format of these time estimates affect customers’ satisfaction? In particular, should companies provide customers with a point estimate representing the best estimate, or should they communicate the inherent uncertainty in outcomes by providing a range estimate? In eight preregistered experiments (N = 5,323), participants observed time estimates provided by an app, and we manipulated whether the app presented the time estimates as a point estimate (e.g., “Your food will arrive in 45 minutes.”) or a range (e.g., “Your food will arrive in 40–50 minutes.”). After participants learned about the app’s prediction performance by sampling a set of past outcomes, we measured participants’ evaluation of the app. We find that participants judged the app more positively when it provided a range rather than a point estimate. These results held across different domains, different time durations, different underlying outcome distributions, and an incentive-compatible design. We also find that this preference is not simply due to people’s dislike of late outcomes, as participants also rated ranges more positively than conservative point estimates corresponding to the upper (i.e., later) bound of the range. These findings suggest that companies can increase customer satisfaction with realized time estimates by communicating the uncertainty inherent in these time estimates.},
  summary={Imagine being told your food will arrive in 45 minutes and watching the clock as it’s late, vs. being told 40–50 minutes and getting the same late delivery. Nothing about the delivery has changed, but the experience, in particular, your satisfaction often has. This paper examines how precise time estimates can backfire in inherently uncertain settings: point estimates create narrow expectations that can be easily violated, while ranges prepare people for future variability. When future outcomes are inherently uncertain, how time is communicated can matter as much as when the outcome occurs.},
  conferences={Peer-reviewed conference talks at the Behavioral Decision Research in Management (BDRM) 2024, the Society for Consumer Psychology (SCP) 2022 and the Association of Consumer Research (ACR) 2021.},    
  work={false}
}

@article{hu2026choice,
  title={Choice Set Size Neglect in Predicting Others' Preferences.},
  author={Hu, Beidi and Moon, Alice and VanEpps, Eric},
  journal={Psychological Science},
  year={2026},
  publisher={APA},
  doi={https://doi.org/10.1177/09567976251400333},
  pdf={https://drive.google.com/file/d/1XdQY3ojmJGa25bNS_8MxItnJ8SSvqbAU/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5708322},
  supp={https://drive.google.com/file/d/1BQg2tnA7vGHSK9ipjPvPK1q5ZiENnJYh/view?usp=sharing},
  researchbox={https://researchbox.org/755},
  abstract={An inherent feature of any choice is the set size from which that choice is made—i.e., the number of available options in a choice set. Choice set size impacts the likelihood of landing on a more-preferred option: Larger sets are more likely to contain an option matching one’s preferences. Despite this, six preregistered experiments (N = 10,092 U.S. adults) demonstrate that people consistently underestimate the effect of set size when predicting others’ liking for a chosen option. We propose this effect arises because, although people recognize that set size predicts liking of a chosen option, they typically fail to attend to it when considering others’ choices. As such, this effect attenuates when attention is drawn to set size, specifically: (a) when considering multiple set sizes simultaneously, (b) when the decision process is framed as ranking rather than choosing, or (c) when prompted to recall set size before predicting others’ preferences.},
  summary={Imagine watching a friend order chocolate ice cream every time you go to the same small corner store. Would you conclude that chocolate is their favorite flavor? Now imagine going with them to a shop with dozens of flavors, where they still choose chocolate. Although that choice is the same, its meaning is not. This paper examines a simple mistake we often make when interpreting others’ choices: we focus on what they choose and overlook how many alternatives they had. Choosing an option from a smaller set conveys much less information about one's preference than choosing the same option from a larger set (this is mathematically true). Yet observers tend to underweight the choice context and treat these choices as almost equally revealing.},
  conferences={Peer-reviewed conference talks at the Society for Consumer Psychology (SCP) 2023 and the Association of Consumer Research (ACR) 2022.},  
  work={false}
}

