---
---

@article{hu2026when,
  title={When Goods Were Odds: Do People Prefer Goods that Stem from Uncertainty?},
  author={Hu*, Beidi and Yin*, Siyuan and Moon*, Alice},
  year={2025},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4001081},
  researchbox={https://researchbox.org/454&PEER_REVIEW_passcode=DZKWRE},
  abstract={Much of the uncertainty people face is eventually resolved (e.g., a person entered in a raffle eventually learns what prize they have received). How do people evaluate goods (e.g., prizes) resulting from uncertainty (e.g., raffles)? Seven experiments (total N = 12,128) provide evidence for an uncertainty spillover effect: People prefer goods originating from uncertain prospects compared to those that were always known. This effect appears both with naturalistic scenarios (Study 1) and with incentive-compatible decisions (Study 2). We propose this effect arises because uncertainty induces a perception that the outcome is superior relative to salient downward counterfactuals (Study 3). Supporting this idea, this effect: (a) weakened when downward counterfactuals were salient for certain goods (Study 4), (b) weakened when the worst outcome from uncertainty was realized (Study 5), and (c) reversed when uncertainty involved losses (Study 6). Lastly, this effect carried over to products associated with previously uncertain goods (Study 7). These findings demonstrate that the influence of uncertainty persists beyond its resolution, shaping the evaluation of goods derived from uncertainty.},
  summary={The influence of uncertainty persists even after its resolution, affecting how (sure) options arising from uncertainty are evaluated.},
  work={true}
}

@article{hu2026what,
  title={What are the Different Types of Uncertainty?},
  author={Gaertig*, Celia and Hu*, Beidi and Simmons, Joseph P.},
  year={2025},
  summary={We find that perceptions of epistmic and aleatory uncertainty change not only by uncertainty type but also by amount of uncertainty.},
  work={true}
}

@article{hu2026thinking,
  title={People Think Off the Margin: Preferentially Improving Outcomes That Are Already More Valuable.},
  author={Lewis, Joshua and Hu, Beidi},
  year={2024},
  psycharchives={https://psycharchives.org/en/item/2e3bc503-eda3-4ad8-b769-a9ac2007aeb2},
  researchbox={https://researchbox.org/3191&PEER_REVIEW_passcode=WDPVUQ},
  abstract={Throughout life, people must decide whether to pursue costly improvements to outcomes they care about. According to classical economics, people think at the margin: that is, they weigh the marginal benefit from an incremental improvement in the outcome against its marginal cost (1). Additionally, economists often assume diminishing marginal benefits from wealth and consumption (2). Thus, there is more marginal benefit from improving a reward from $20 to $30 than from $70 to $80, and even more marginal benefit from reducing a loss from $30 to $20. Similarly, psychologists typically assume diminishing sensitivity to gains and loss aversion (3), implying the same pattern. Yet, contrary to what marginal thinking would predict, across seven experiments (total N = 5,864, five with real consequences), participants tended to improve more versus less favorable outcomes, improving gains more than losses and larger gains more than smaller gains. That is, our participants thought off the margin: they decided on improvements based on the total value of the outcomes, not just the incremental change in their value. We propose that people think off the margin because attaining improvements requires motivation and, in general, people are more motivated to take actions with which they have more positive associations (4). People have more positive associations with improvements when the potential outcomes are more valuable in total, even if the marginal improvement in those outcomes is very small. Thus, in life, people might waste resources improving what is already valuable and neglect to improve what is in need of improvement.},
  summary={Contrary to classical economics and marginal thinking, people invest more in improving better outcomes than worse outcomes.},
  work={true}
}


@article{hu2023does,
  title={Does Constructing a Belief Distribution Truly Reduce Overconfidence?},
  author={Hu, Beidi and Simmons, Joseph P},
  journal={Journal of Experimental Psychology: General},
  volume={152},
  number={2},
  pages={571},
  year={2023},
  publisher={American Psychological Association},
  doi={https://doi.org/10.1037/xge0001291},
  pdf={https://drive.google.com/file/d/1VQeJd3eVyDd2tWwKvoVtk_wrmSZqFO6C/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4180883},
  supp={https://drive.google.com/file/d/1V68oK10_pcPcvWKorgNAS-GfnTqOHLO1/view?usp=sharing},
  researchbox={https://researchbox.org/314},
  abstract={Can overconfidence be reduced by asking people to provide a belief distribution over all possible outcomes—that is, by asking them to indicate how likely all possible outcomes are? Although prior research suggests that the answer is “yes,” that research suffers from methodological confounds that muddle its interpretation. In our research, we remove these confounds to investigate whether providing a belief distribution truly reduces overconfidence. In 10 studies, participants made predictions about upcoming sports games or other participants’ preferences, and then indicated their confidence in these predictions using rating scales, likelihood judgments, and/or incentivized wagers. Contrary to prior research, and to our own expectations, we find that providing a belief distribution usually increases overconfidence, because doing so seems to reinforce people’s prior beliefs.},
  summary={Past work says yes. Our paper finds the opposite.},
  work={false}
}

@article{hu2025different,
  title={Different Methods Elicit Different Belief Distributions.},
  author={Hu, Beidi and Simmons, Joseph P},
  journal={Journal of Experimental Psychology: General},
  volume={154},
  number={2},
  pages={476},
  year={2025},
  publisher={American Psychological Association},
  doi={https://doi.org/10.1037/xge0001655},
  pdf={https://drive.google.com/file/d/1ICWKU2mY7NsI6m6bhYRP2AUKXPzTm7J6/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4926793},
  supp={https://drive.google.com/file/d/1W6q1PN-IjHcYKfeH4igSL8iUo3vOlbZv/view?usp=sharing},
  researchbox={https://researchbox.org/569},
  abstract={When eliciting people’s forecasts or beliefs, you can ask for a point estimate—for example, what is the most likely state of the world?—or you can ask for an entire distribution of beliefs—for example, how likely is every possible state of the world? Eliciting belief distributions potentially yields more information, and researchers have increasingly tried to do so. In this article, we show that different elicitation methods elicit different belief distributions. We compare two popular methods used to elicit belief distributions: Distribution Builder and Sliders. In 10 preregistered studies (N = 14,553), we find that Distribution Builder elicits more accurate belief distributions than Sliders, except when true distributions are right-skewed, for which the results are mixed. This result holds when we assess accuracy (a) relative to a normative benchmark and (b) relative to participants’ own beliefs. Our evidence suggests that participants approach these two methods differently: Sliders users are more likely to start with the lowest bins in the interface, which in turn leads them to put excessive mass in those bins. Our research sheds light on the process by which people construct belief distributions while offering a practical recommendation for future research: All else equal, Distribution Builder yields more accurate belief distributions.},
  summary={Belief distribution elicitations are on the rise. We find that two functionally equivalent methods elicit different belief distributions.},
  work={false}
}

@article{hu2025should,
  title={How Should Time Estimates Be Structured to Increase Customer Satisfaction?},
  author={Hu, Beidi and Gaertig, Celia and Dietvorst, Berkeley J},
  journal={Management Science},
  volume={71},
  number={9},
  pages={7497},
  year={2025},
  publisher={INFORMS},
  doi={https://doi.org/10.1287/mnsc.2023.00137},
  pdf={https://drive.google.com/file/d/1NutuW7y_iAOzTc7ZSVKkAJtM1I5NOI57/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4927151},
  supp={https://drive.google.com/file/d/1auz8ySRF948fTKYOlxUJXZ9DKX5arl7i/view?usp=sharing},
  researchbox={https://researchbox.org/482},
  abstract={Businesses across industries, such as food delivery apps and GPS navigation systems, routinely provide customers with time estimates in inherently uncertain contexts. How does the format of these time estimates affect customers’ satisfaction? In particular, should companies provide customers with a point estimate representing the best estimate, or should they communicate the inherent uncertainty in outcomes by providing a range estimate? In eight preregistered experiments (N = 5,323), participants observed time estimates provided by an app, and we manipulated whether the app presented the time estimates as a point estimate (e.g., “Your food will arrive in 45 minutes.”) or a range (e.g., “Your food will arrive in 40–50 minutes.”). After participants learned about the app’s prediction performance by sampling a set of past outcomes, we measured participants’ evaluation of the app. We find that participants judged the app more positively when it provided a range rather than a point estimate. These results held across different domains, different time durations, different underlying outcome distributions, and an incentive-compatible design. We also find that this preference is not simply due to people’s dislike of late outcomes, as participants also rated ranges more positively than conservative point estimates corresponding to the upper (i.e., later) bound of the range. These findings suggest that companies can increase customer satisfaction with realized time estimates by communicating the uncertainty inherent in these time estimates.},
  summary={Customers judge a digital platform (e.g., food delivery app, GPS app) more positively when it provides time estimates as ranges rather than point estimates.},
  work={false}
}

@article{hu2026choice,
  title={Choice Set Size Neglect in Predicting Others' Preferences.},
  author={Hu, Beidi and Moon, Alice and VanEpps, Eric},
  journal={Psychological Science},
  year={2026},
  publisher={APA},
  doi={https://doi.org/10.1177/09567976251400333},
  pdf={https://drive.google.com/file/d/1XdQY3ojmJGa25bNS_8MxItnJ8SSvqbAU/view?usp=sharing},
  ssrn={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5708322},
  supp={https://drive.google.com/file/d/1BQg2tnA7vGHSK9ipjPvPK1q5ZiENnJYh/view?usp=sharing},
  researchbox={https://researchbox.org/755},
  abstract={An inherent feature of any choice is the set size from which that choice is made—i.e., the number of available options in a choice set. Choice set size impacts the likelihood of landing on a more-preferred option: Larger sets are more likely to contain an option matching one’s preferences. Despite this, six preregistered experiments (N = 10,092 U.S. adults) demonstrate that people consistently underestimate the effect of set size when predicting others’ liking for a chosen option. We propose this effect arises because, although people recognize that set size predicts liking of a chosen option, they typically fail to attend to it when considering others’ choices. As such, this effect attenuates when attention is drawn to set size, specifically: (a) when considering multiple set sizes simultaneously, (b) when the decision process is framed as ranking rather than choosing, or (c) when prompted to recall set size before predicting others’ preferences.},
  summary={Although every choice comes with a set size, people consistently underestimate how it influences others’ preferences when observing their choices.},
  conferences={Peer-reviewed conference talk presented at the Society for Consumer Psychology (SCP) 2023 in San Juan, Puerto Rico, and the Association of Consumer Research (ACR) 2022 in Denver, CO.},  
  work={false}
}

